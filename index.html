<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>This is my paper title</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Enhancing the Robustness of AEROBLADE Against Post-Processing Techniques" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">Enhancing the Robustness of AEROBLADE Against Post-Processing Techniques</span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://anisundar18.github.io">Anirudh Sundara Rajan</a></span>
						</center>
					</td>

				</tr>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/AniSundar18/aeroblade_mod/tree/main'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:500px" src="./resources/teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					This was a template originally made for <a href="http://richzhang.github.io/colorization/">Colorful Image Colorization</a>. The code can be found in this <a href="https://github.com/richzhang/webpage-template">repository</a>.
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Reconstruction-based fake image detection techniques have gained significant attention recently. One such approach is AEROBLADE, a method designed to detect images generated by latent diffusion models. AEROBLADE leverages the autoencoder of the latent diffusion model to reconstruct a given image. If the reconstructed image closely resembles the original, the image is classified as fake, as it is likely to have originated from the generative model. However, the core assumption of this method is that the image comes directly from the diffusion model. This reliance renders the technique vulnerable to post-processing operations, as post-processed images no longer directly originate from the diffusion model. To address this limitation, we propose a simple yet effective modification. Instead of relying on the LPIPS distance between the image and its reconstruction, we train a classifier that inputs the difference between the original image and its reconstruction (similar to the approach used in DIRE). Our experiments show that training a network on these differences significantly improves detection performance, particularly for post-processed images, compared to the original AEROBLADE method.
			</td>
		</tr>
	</table>
	<br>

	<hr>
		<center><h1>AEROBLADE Struggles with Post-Processing</h1></center>
		
		<td width=260px>
					<center>
						<img class="round" style="width:800px; height:400px" src="./resources/aero_fault.png"/>
					</center>
				</td>
		
		<p align="left"">
    <a href="https://arxiv.org/abs/2401.17879">AEROBLADE</a> is a method specific to detecting images from latent diffusion models which works as follows:
    (i) Select a Latent Diffusion model of interest (e.g., Stable Diffusion),
    (ii) Attempt to find the closest latent by using the encoder, and pass that latent through the decoder to obtain the reconstruction, and
    (iii) Measure the distance between the original image and the reconstruction, based on which a decision can be made.<br><br>
    However, this approach only works in simple lab settings where the fake images have not undergone any kind of post-processing. Intuitively, the post-processed images did not directly come from a latent, therefore the reconstruction error increases. This can be seen in the above figure, where in the left, the AEROBLADE is able to separate the real and fake distributions,  however once post-processing is applied, the distributions are not separable. However, it is important to note that the distance of real images from their reconstructions remains similar, only the distance of the fake images from their reconstructions increases further supporting the hypothesis presented earlier. We attempt to fix some of these problems.
</p>
		
	<hr>

	<hr>
		<center><h1>Choice of Distance Metric</h1></center>
		
		
		
		<p align="left"">
    The current hypothesis is that there exists no latent that can accurately reconstruct the post-processed image. Based on that hypothesis, we first investigate whether we can find a distance metric that is invariant to these post-processing operations. That way, we can simply replace LPIPS with this new metric and improve the existing detector. For our metric, we use the representations of the <a href="https://arxiv.org/abs/2103.00020">CLIP</a> Vision Transformer. Given the vast number of images seen by CLIP, it is reasonable to expect invariance to post-processing operations. We explore 2 variants which we illustrate below,in our first variant on the left, we calculate the euclidean distance between the class tokens, and in the variant on the right, we calculate the token-wise distance and average them. 
</p>
		<td width=260px>
					<center>
						<img class="round" style="width:800px; height:400px" src="./resources/New_dist.png"/>
					</center>
				</td>
		<p align="left"">
			To determine which layer's feature space to use, we conduct a simple experiment by analyzing the rough performance. As shown in the figure below, we select layer 12 for distances computed using only the CLS token and layer 8 for the average token-wise distance. We use a dataset of images which have been generated by SDv1.5 and saved with various post-processing operations.
		</p>
	<td width=260px>
					<center>
						<img class="round" style="width:800px; height:400px" src="./resources/layerwise.png"/>
					</center>
				</td>
	<p align="left"">
	We compare the effectiveness of the new distance metric against the original LPIPS used by the AEROBLADE in the below figure. For our experiments, we use images generated using prompts pertaining to classes from CIFAR-100 and prompts taken from <a href="https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts">Gustavosta</a>. The results show that using the CLIP based distance metric comprehensively outperforms using the LPIPS-based distance metric, especially in settings where there is JPG compression and other forms of post-processing. However, the performance could still be greatly improved.
		</p>
	<hr>
	<td width=260px>
					<center>
						<img class="round" style="width:800px; height:400px" src="./resources/dist_comps.png"/>
					</center>
				</td>

	<center><h1>Code</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:450px" src="./resources/method_diagram.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Short description if wanted
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/richzhang/webpage-template'>[GitHub]</a>
			</center>
		</span>
	</table>
	<br>
	<hr>
	<table align=center width=450px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">F. Author, S. Author, T. Author.<br>
				<b>Creative and Descriptive Paper Title.</b><br>
				In Conference, 20XX.<br>
				(hosted on <a href="">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

